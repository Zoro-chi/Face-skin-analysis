{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6fce0b5",
   "metadata": {},
   "source": [
    "# Face Skin Condition Analysis - Colab Training\n",
    "## Step-by-step GPU training with proper setup\n",
    "\n",
    "**Prerequisites:**\n",
    "- Upload `face-skin-analysis.tar.gz` (194MB) to your Google Drive root\n",
    "- Select GPU runtime: Runtime ‚Üí Change runtime type ‚Üí GPU (T4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582a48d",
   "metadata": {},
   "source": [
    "## üîó Step 1: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d378efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print('‚úÖ Google Drive mounted!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706bf82b",
   "metadata": {},
   "source": [
    "## üì¶ Step 2: Extract Project Archive\n",
    "\n",
    "**Important:** Make sure you've uploaded `face-skin-analysis.tar.gz` to your Google Drive root!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if archive exists\n",
    "archive_path = '/content/drive/MyDrive/face-skin-analysis.zip'\n",
    "project_path = '/content/Face-skin-analysis'\n",
    "\n",
    "if not os.path.exists(archive_path):\n",
    "    print('‚ùå ERROR: archive not found in Google Drive!')\n",
    "    print('Please upload the zip to your Google Drive root folder.')\n",
    "else:\n",
    "    print(f'‚úÖ Archive found: {archive_path}')\n",
    "    \n",
    "    # Create project directory if it doesn't exist\n",
    "    os.makedirs(project_path, exist_ok=True)\n",
    "    \n",
    "    # Check if already extracted (look for key files)\n",
    "    if not os.path.exists(os.path.join(project_path, 'configs')):\n",
    "        print('üì¶ Extracting project... (this may take 1-2 minutes)')\n",
    "        # Use unzip for the .zip archive\n",
    "        !unzip -q {archive_path} -d {project_path}\n",
    "        print('‚úÖ Extraction complete!')\n",
    "    else:\n",
    "        print('‚úÖ Project already extracted!')\n",
    "    \n",
    "    # Verify extraction\n",
    "    print('\\nüìÇ Project contents:')\n",
    "    !ls -la {project_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a2385",
   "metadata": {},
   "source": [
    "## üîß Step 3: Navigate to Project & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3cbac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to project directory\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_path = '/content/Face-skin-analysis'\n",
    "os.chdir(project_path)\n",
    "print(f'üìÇ Current directory: {os.getcwd()}')\n",
    "\n",
    "# Add to Python path (use the same path)\n",
    "sys.path.insert(0, project_path)\n",
    "\n",
    "print('‚úÖ Python path configured!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab9524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Update config base_dir for Colab to use /content\n",
    "import yaml\n",
    "cfg_path = '/content/Face-skin-analysis/configs/config.yaml'\n",
    "with open(cfg_path, 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "cfg.setdefault('environment', {}).setdefault('colab', {})['base_dir'] = '/content/Face-skin-analysis'\n",
    "with open(cfg_path, 'w') as f:\n",
    "    yaml.dump(cfg, f, default_flow_style=False, indent=2)\n",
    "print('‚úÖ Updated configs/config.yaml base_dir to /content/Face-skin-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561304eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print('‚úÖ Dependencies installed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93ad0be",
   "metadata": {},
   "source": [
    "## üéÆ Step 4: Verify GPU & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55841a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check GPU\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB')\n",
    "else:\n",
    "    print('‚ö†Ô∏è WARNING: No GPU detected! Go to Runtime ‚Üí Change runtime type ‚Üí Select GPU')\n",
    "\n",
    "# Now import project modules\n",
    "from utils.environment import get_environment\n",
    "\n",
    "env = get_environment()\n",
    "print(f'\\n‚úÖ Environment: {env}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c9ffc",
   "metadata": {},
   "source": [
    "## üìä Step 5: Verify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4540b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check processed data\n",
    "print('üìä Checking processed data...')\n",
    "!ls -lh data/processed/\n",
    "\n",
    "print('\\nüìÑ Data splits:')\n",
    "!wc -l data/processed/train.csv data/processed/val.csv data/processed/test.csv\n",
    "\n",
    "print('\\n‚úÖ Data verification complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a8c5e",
   "metadata": {},
   "source": [
    "## üîç Step 5a: Check Skin Tone Distribution (Diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d27bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check skin tone distribution in splits\n",
    "print(\"üìä Skin Tone Distribution Analysis\\n\")\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    df = pd.read_csv(f'data/processed/{split}.csv')\n",
    "    print(f\"{split.upper()} SET:\")\n",
    "    print(f\"  Total samples: {len(df)}\")\n",
    "    \n",
    "    if 'skin_tone' in df.columns:\n",
    "        counts = df['skin_tone'].value_counts()\n",
    "        print(f\"  Skin tone values:\\n{counts}\\n\")\n",
    "        \n",
    "        # Check if any valid Fitzpatrick values exist\n",
    "        valid_fitz = df['skin_tone'].isin(['1', '2', '3', '4', '5', '6', 1, 2, 3, 4, 5, 6])\n",
    "        print(f\"  Valid Fitzpatrick labels: {valid_fitz.sum()}/{len(df)}\\n\")\n",
    "    else:\n",
    "        print(\"  ‚ùå No skin_tone column found\\n\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è If all values are 'unknown', balanced sampling won't work!\")\n",
    "print(\"Solution: Re-run preprocessing with Fitzpatrick17k metadata extraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420791e3",
   "metadata": {},
   "source": [
    "## üîß Step 5b: Fix Skin Tones (Run if all are 'unknown')\n",
    "\n",
    "**Only run this if Step 5a showed all skin_tone values as 'unknown'**\n",
    "\n",
    "This will:\n",
    "1. Re-extract Fitzpatrick17k metadata to get real skin tone labels (1-6)\n",
    "2. Regenerate metadata.csv and train/val/test splits with skin tones\n",
    "3. Enable balanced sampling for fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d13db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: This recreates metadata and splits (loses current train/val/test split)\n",
    "# Only run if you need skin tone labels for fairness analysis\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"üîß Regenerating metadata with Fitzpatrick skin tone labels...\")\n",
    "print(\"‚ö†Ô∏è This will create new train/val/test splits!\\n\")\n",
    "\n",
    "# Run preprocessing to extract skin tones from Fitzpatrick17k metadata\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"preprocessing/run.py\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Errors:\", result.stderr)\n",
    "\n",
    "# Verify skin tones were extracted\n",
    "print(\"\\nüìä Verifying skin tone extraction...\")\n",
    "df = pd.read_csv('data/processed/train.csv')\n",
    "counts = df['skin_tone'].value_counts()\n",
    "print(f\"Skin tone distribution:\\n{counts}\")\n",
    "\n",
    "valid_fitz = df['skin_tone'].isin(['1', '2', '3', '4', '5', '6'])\n",
    "print(f\"\\n‚úÖ Valid Fitzpatrick labels: {valid_fitz.sum()}/{len(df)}\")\n",
    "\n",
    "if valid_fitz.sum() > 0:\n",
    "    print(\"\\nüéâ Success! Balanced sampling will now work in training.\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Still no valid skin tones. Check Fitzpatrick17k dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a37f4b5",
   "metadata": {},
   "source": [
    "## üß™ Step 6: Test Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2332b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.data_loader import create_data_loaders\n",
    "from utils.config_loader import load_config\n",
    "\n",
    "# Load config\n",
    "config = load_config('configs/config.yaml')\n",
    "\n",
    "# Create data loaders (returns a dictionary)\n",
    "data_loaders = create_data_loaders(config)\n",
    "train_loader = data_loaders['train']\n",
    "val_loader = data_loaders['val']\n",
    "test_loader = data_loaders['test']\n",
    "\n",
    "print(f'‚úÖ Train batches: {len(train_loader)}')\n",
    "print(f'‚úÖ Val batches: {len(val_loader)}')\n",
    "print(f'‚úÖ Test batches: {len(test_loader)}')\n",
    "\n",
    "# Test a batch\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f'\\nüì¶ Batch shape: {images.shape}')\n",
    "print(f'üì¶ Labels shape: {labels.shape}')\n",
    "print(f'üéØ Device: {images.device}')\n",
    "\n",
    "print('\\n‚úÖ Data loaders working correctly!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462060b8",
   "metadata": {},
   "source": [
    "## üîê Step 7: Setup MLflow (Optional - Skip for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e909a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Option 1: Disable MLflow tracking (recommended for first run)\n",
    "os.environ['MLFLOW_TRACKING_URI'] = ''\n",
    "print('‚úÖ MLflow tracking disabled (training will be faster)')\n",
    "\n",
    "# Option 2: Enable DagsHub tracking (uncomment if you have credentials)\n",
    "# os.environ['MLFLOW_TRACKING_USERNAME'] = 'your-dagshub-username'\n",
    "# os.environ['MLFLOW_TRACKING_PASSWORD'] = 'your-dagshub-token'\n",
    "# print('‚úÖ MLflow tracking enabled')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8d79a",
   "metadata": {},
   "source": [
    "## üöÄ Step 8: Start Training!\n",
    "\n",
    "This will take 2-3 hours on a T4 GPU. You can monitor progress in the output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ebcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "!python training/train.py\n",
    "\n",
    "# Note: Training progress will show in the output below\n",
    "# Checkpoints are automatically saved to outputs/checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d7d57",
   "metadata": {},
   "source": [
    "## üìà Step 9: Monitor Training (Run these periodically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU usage\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List saved checkpoints\n",
    "!ls -lh outputs/checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e82784",
   "metadata": {},
   "source": [
    "## üìä Step 10: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0f26ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation with bias analysis\n",
    "!python evaluation/evaluate.py\n",
    "\n",
    "print('\\n‚úÖ Evaluation complete!')\n",
    "print('Results saved to outputs/evaluation/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0abb4a1",
   "metadata": {},
   "source": [
    "## üìä Step 10a: Debug Bias Analysis (Diagnostic)\n",
    "\n",
    "**Run this to diagnose why bias metrics show 0.0000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load test CSV\n",
    "test_df = pd.read_csv('data/processed/test.csv')\n",
    "\n",
    "print(\"üîç Checking Test Set Skin Tone Mapping\\n\")\n",
    "\n",
    "# Check raw skin_tone values\n",
    "print(\"Raw skin_tone distribution:\")\n",
    "print(test_df['skin_tone'].value_counts())\n",
    "\n",
    "# Map to groups using config logic\n",
    "tone_map = {'1': 'light', '2': 'light', '3': 'medium', '4': 'medium', '5': 'dark', '6': 'dark'}\n",
    "\n",
    "def to_group(x):\n",
    "    x_clean = str(x).strip()\n",
    "    return tone_map.get(x_clean, 'unknown')\n",
    "\n",
    "test_df['tone_group'] = test_df['skin_tone'].apply(to_group)\n",
    "\n",
    "print(\"\\nMapped to groups:\")\n",
    "print(test_df['tone_group'].value_counts())\n",
    "\n",
    "# Check if any positives exist per group\n",
    "print(\"\\nüìä Positives per skin tone group:\")\n",
    "for group in ['light', 'medium', 'dark']:\n",
    "    group_df = test_df[test_df['tone_group'] == group]\n",
    "    print(f\"\\n{group.upper()} (n={len(group_df)}):\")\n",
    "    print(f\"  has_acne: {group_df['has_acne'].sum()}\")\n",
    "    print(f\"  has_pigmentation: {group_df['has_pigmentation'].sum()}\")\n",
    "    print(f\"  has_wrinkles: {group_df['has_wrinkles'].sum()}\")\n",
    "\n",
    "# The issue: bias_analysis averages across ALL conditions using macro average\n",
    "# If some groups have 0 positives for a condition, division by zero ‚Üí 0.0\n",
    "print(\"\\n‚ö†Ô∏è If a group has 0 positives for ANY condition, macro avg precision/recall = 0.0\")\n",
    "print(\"This is a sklearn limitation with multi-label classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9774f032",
   "metadata": {},
   "source": [
    "## ‚úÖ Bias Analysis Fix Applied\n",
    "\n",
    "**Problem:** Previous evaluation showed all bias metrics as 0.0000 despite valid skin tone labels.\n",
    "\n",
    "**Root Cause:** Using `average=\"macro\"` with multi-label classification returns 0.0 when any condition has zero positives in a group.\n",
    "\n",
    "**Solution:** Changed to `average=\"samples\"` which is appropriate for multi-label classification.\n",
    "\n",
    "**Expected Results:**\n",
    "- Non-zero precision, recall, F1 for all skin tone groups\n",
    "- Per-condition breakdown showing performance by group\n",
    "- New visualization: `per_condition_metrics.png` with detailed comparisons\n",
    "\n",
    "**See:** `docs/BIAS_ANALYSIS_FIX.md` for complete technical details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f14ac",
   "metadata": {},
   "source": [
    "## üì• Step 11: Download Results\n",
    "\n",
    "All outputs are saved in Google Drive. You can access them directly from Drive or download specific files below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15551f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download trained model\n",
    "print('Downloading best model...')\n",
    "files.download('outputs/checkpoints/best_model.pth')\n",
    "\n",
    "# Download evaluation metrics (if available)\n",
    "import os\n",
    "if os.path.exists('outputs/evaluation/metrics.json'):\n",
    "    print('Downloading metrics...')\n",
    "    files.download('outputs/evaluation/metrics.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9465914b",
   "metadata": {},
   "source": [
    "## üéâ Training Complete!\n",
    "\n",
    "**What you've accomplished:**\n",
    "- ‚úÖ Trained a skin condition detection model on GPU\n",
    "- ‚úÖ Evaluated performance with bias analysis\n",
    "- ‚úÖ Model saved to Google Drive\n",
    "\n",
    "**Files in Google Drive:**\n",
    "```\n",
    "Face-skin-analysis/\n",
    "‚îú‚îÄ‚îÄ outputs/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/best_model.pth\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/last_model.pth\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ evaluation/metrics.json\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ logs/training.log\n",
    "```\n",
    "\n",
    "**Next steps:**\n",
    "1. Review evaluation metrics\n",
    "2. Test model locally with `inference/predict.py`\n",
    "3. Export to ONNX: `python onnx/export.py`\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Tip:** All files persist in Google Drive and can be accessed from your local machine via Google Drive Desktop or web interface."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
