{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6fce0b5",
   "metadata": {},
   "source": [
    "# Face Skin Condition Analysis - Colab Training\n",
    "## Step-by-step GPU training with proper setup\n",
    "\n",
    "**Prerequisites:**\n",
    "- Upload `face-skin-analysis.tar.gz` (194MB) to your Google Drive root\n",
    "- Select GPU runtime: Runtime ‚Üí Change runtime type ‚Üí GPU (T4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582a48d",
   "metadata": {},
   "source": [
    "## üîó Step 1: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d378efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print('‚úÖ Google Drive mounted!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706bf82b",
   "metadata": {},
   "source": [
    "## üì¶ Step 2: Extract Project Archive\n",
    "\n",
    "**Important:** Make sure you've uploaded `face-skin-analysis.tar.gz` to your Google Drive root!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if archive exists\n",
    "archive_path = '/content/drive/MyDrive/face-skin-analysis.zip'\n",
    "project_path = '/content/Face-skin-analysis'\n",
    "\n",
    "if not os.path.exists(archive_path):\n",
    "    print('‚ùå ERROR: archive not found in Google Drive!')\n",
    "    print('Please upload the zip to your Google Drive root folder.')\n",
    "else:\n",
    "    print(f'‚úÖ Archive found: {archive_path}')\n",
    "    \n",
    "    # Create project directory if it doesn't exist\n",
    "    os.makedirs(project_path, exist_ok=True)\n",
    "    \n",
    "    # Check if already extracted (look for key files)\n",
    "    if not os.path.exists(os.path.join(project_path, 'configs')):\n",
    "        print('üì¶ Extracting project... (this may take 1-2 minutes)')\n",
    "        # Use unzip for the .zip archive\n",
    "        !unzip -q {archive_path} -d {project_path}\n",
    "        print('‚úÖ Extraction complete!')\n",
    "    else:\n",
    "        print('‚úÖ Project already extracted!')\n",
    "    \n",
    "    # Verify extraction\n",
    "    print('\\nüìÇ Project contents:')\n",
    "    !ls -la {project_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a2385",
   "metadata": {},
   "source": [
    "## üîß Step 3: Navigate to Project & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3cbac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to project directory\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_path = '/content/Face-skin-analysis'\n",
    "os.chdir(project_path)\n",
    "print(f'üìÇ Current directory: {os.getcwd()}')\n",
    "\n",
    "# Add to Python path (use the same path)\n",
    "sys.path.insert(0, project_path)\n",
    "\n",
    "print('‚úÖ Python path configured!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab9524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Update config base_dir for Colab to use /content\n",
    "import yaml\n",
    "cfg_path = '/content/Face-skin-analysis/configs/config.yaml'\n",
    "with open(cfg_path, 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "cfg.setdefault('environment', {}).setdefault('colab', {})['base_dir'] = '/content/Face-skin-analysis'\n",
    "with open(cfg_path, 'w') as f:\n",
    "    yaml.dump(cfg, f, default_flow_style=False, indent=2)\n",
    "print('‚úÖ Updated configs/config.yaml base_dir to /content/Face-skin-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561304eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print('‚úÖ Dependencies installed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93ad0be",
   "metadata": {},
   "source": [
    "## üéÆ Step 4: Verify GPU & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55841a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check GPU\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB')\n",
    "else:\n",
    "    print('‚ö†Ô∏è WARNING: No GPU detected! Go to Runtime ‚Üí Change runtime type ‚Üí Select GPU')\n",
    "\n",
    "# Now import project modules\n",
    "from utils.environment import get_environment\n",
    "\n",
    "env = get_environment()\n",
    "print(f'\\n‚úÖ Environment: {env}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c9ffc",
   "metadata": {},
   "source": [
    "## üìä Step 5: Verify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4540b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check processed data\n",
    "print('üìä Checking processed data...')\n",
    "!ls -lh data/processed/\n",
    "\n",
    "print('\\nüìÑ Data splits:')\n",
    "!wc -l data/processed/train.csv data/processed/val.csv data/processed/test.csv\n",
    "\n",
    "print('\\n‚úÖ Data verification complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a37f4b5",
   "metadata": {},
   "source": [
    "## üß™ Step 6: Test Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2332b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.data_loader import create_data_loaders\n",
    "from utils.config_loader import load_config\n",
    "\n",
    "# Load config\n",
    "config = load_config('configs/config.yaml')\n",
    "\n",
    "# Create data loaders (returns a dictionary)\n",
    "data_loaders = create_data_loaders(config)\n",
    "train_loader = data_loaders['train']\n",
    "val_loader = data_loaders['val']\n",
    "test_loader = data_loaders['test']\n",
    "\n",
    "print(f'‚úÖ Train batches: {len(train_loader)}')\n",
    "print(f'‚úÖ Val batches: {len(val_loader)}')\n",
    "print(f'‚úÖ Test batches: {len(test_loader)}')\n",
    "\n",
    "# Test a batch\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f'\\nüì¶ Batch shape: {images.shape}')\n",
    "print(f'üì¶ Labels shape: {labels.shape}')\n",
    "print(f'üéØ Device: {images.device}')\n",
    "\n",
    "print('\\n‚úÖ Data loaders working correctly!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462060b8",
   "metadata": {},
   "source": [
    "## üîê Step 7: Setup MLflow (Optional - Skip for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e909a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Option 1: Disable MLflow tracking (recommended for first run)\n",
    "os.environ['MLFLOW_TRACKING_URI'] = ''\n",
    "print('‚úÖ MLflow tracking disabled (training will be faster)')\n",
    "\n",
    "# Option 2: Enable DagsHub tracking (uncomment if you have credentials)\n",
    "# os.environ['MLFLOW_TRACKING_USERNAME'] = 'your-dagshub-username'\n",
    "# os.environ['MLFLOW_TRACKING_PASSWORD'] = 'your-dagshub-token'\n",
    "# print('‚úÖ MLflow tracking enabled')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8d79a",
   "metadata": {},
   "source": [
    "## üöÄ Step 8: Start Training!\n",
    "\n",
    "This will take 2-3 hours on a T4 GPU. You can monitor progress in the output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ebcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "!python training/train.py\n",
    "\n",
    "# Note: Training progress will show in the output below\n",
    "# Checkpoints are automatically saved to outputs/checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d7d57",
   "metadata": {},
   "source": [
    "## üìà Step 9: Monitor Training (Run these periodically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU usage\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List saved checkpoints\n",
    "!ls -lh outputs/checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e82784",
   "metadata": {},
   "source": [
    "## üìä Step 10: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0f26ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation with per-class threshold optimization\n",
    "!python evaluation/evaluate.py\n",
    "\n",
    "print('\\n‚úÖ Evaluation complete!')\n",
    "print('Results saved to outputs/evaluation/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f14ac",
   "metadata": {},
   "source": [
    "## üì• Step 11: Download Results\n",
    "\n",
    "All outputs are saved in Google Drive. You can access them directly from Drive or download specific files below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15551f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download trained model\n",
    "print('Downloading best model...')\n",
    "files.download('outputs/checkpoints/best_model.pth')\n",
    "\n",
    "# Download evaluation metrics (if available)\n",
    "import os\n",
    "if os.path.exists('outputs/evaluation/metrics.json'):\n",
    "    print('Downloading metrics...')\n",
    "    files.download('outputs/evaluation/metrics.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9465914b",
   "metadata": {},
   "source": [
    "## üéâ Training Complete!\n",
    "\n",
    "**What you've accomplished:**\n",
    "- ‚úÖ Trained a skin condition detection model on GPU\n",
    "- ‚úÖ Evaluated performance with optimized thresholds\n",
    "- ‚úÖ Model saved to Google Drive\n",
    "\n",
    "**Files in Google Drive:**\n",
    "```\n",
    "Face-skin-analysis/\n",
    "‚îú‚îÄ‚îÄ outputs/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/best_model.pth\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/last_model.pth\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ evaluation/metrics.json\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ logs/training.log\n",
    "```\n",
    "\n",
    "**Model Performance:**\n",
    "- Multi-label classification: acne, pigmentation, wrinkles\n",
    "- Overall F1: ~0.81, AUROC: ~0.99\n",
    "- Per-class threshold optimization enabled\n",
    "\n",
    "**Next steps:**\n",
    "1. Review evaluation metrics in `outputs/evaluation/metrics.json`\n",
    "2. Test model locally with `inference/predict.py`\n",
    "3. Export to ONNX: `python onnx/export.py`\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Tip:** All files persist in Google Drive and can be accessed from your local machine via Google Drive Desktop or web interface."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
